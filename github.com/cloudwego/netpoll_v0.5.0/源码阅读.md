
* [例子代码](https://github.com/cloudwego/netpoll-examples/blob/main/server.go)
* [rpc 服务器例子](https://github.com/cloudwego/netpoll-examples/blob/main/mux/mux_server.go)
* 一个简单的服务器的例子:
```go
package main

import (
	"context"
	"log"
	"time"

	"github.com/cloudwego/netpoll"
)

func main() {
	netpoll.SetNumLoops(1)
	netpoll.SetLoadBalance(netpoll.RoundRobin)
	//
	network, address := "tcp", ":8080"
	listener, _ := netpoll.CreateListener(network, address)

	eventLoop, _ := netpoll.NewEventLoop(
		handle,
		netpoll.WithOnPrepare(prepare),
		netpoll.WithReadTimeout(time.Second),
		netpoll.WithIdleTimeout(time.Second*10), // 完全没效果
	)

	// start listen loop ...
	eventLoop.Serve(listener)
}

var _ netpoll.OnPrepare = prepare
var _ netpoll.OnRequest = handle

func prepare(connection netpoll.Connection) context.Context {
	return context.Background()
}

func handle(ctx context.Context, connection netpoll.Connection) error { // onRequest
	connection.SetIdleTimeout(time.Second * 10)
	connection.SetReadDeadline(time.Now().Add(time.Second * 5))
	connection.SetWriteDeadline(time.Now().Add(time.Duration(time.Second * 5)))
	connection.AddCloseCallback(func(connection netpoll.Connection) error {
		log.Println("close")
		return nil
	})
	//connection.SetOnConnect(nil)
	// 猜测应该是每个 tcp 包触发一次
	reader := connection.Reader()
	defer reader.Release()
	msg, _ := reader.ReadString(reader.Len())
	println(msg)
	return nil
}
```

# 文件级别的分析
| sys_epoll_linux.go | epoll 的各个函数的封装 |
| poll_manager.go | 负责 epoll 协程的创建 |
| poll_loadbalance.go | 有新连接发生的时候，选择使用哪一个 epoll_wait 协程 |
| netpoll.go | 用户使用这个库的入口 | 


# 全局初始化
| 源码 | 函数 | 调用了 | 被调函数 | 说明 |
| ---- | ---- | ---- | ---- | ---- |
| poll_manager.go:48 | func init() | :48 | pollmanager.SetNumLoops(loops) | 默认每 20 个核使用一个 epoll 的事件协程 |
| :62 | func (m *manager) SetNumLoops | - | - | 设置事件协程 |
| - | - | - | :86 | return m.Run() | 执行 poll 事件循环 |
| :110 | func (m *manager) Run() | - | - | - |
| - | - | :120 | poll, err = openPoll() | 生成 poll 对象 |
| poll_default_linux.go:26 | openPoll() | - | - | 创建 poll 对象 |
| :30 | func openDefaultPoll() | - | - | - |
| - | - | :34 | var p, err = EpollCreate(0) | 调用系统调用: epoll_create |
| - | - | :38 | poll.fd = p | epoll 的  fd 赋值 |
| - | - | :50 | poll.Control(poll.wop, PollReadable) | 调用  epoll_ctl |
| poll_manager.go:124 | func (m *manager) Run() | - | - | - |
| :124 | - | - | m.polls = append(m.polls, poll) | 把 poll 对象加到 poll 数组 |
| - | - | :125 | go poll.Wait() | 创建事件循环，使用 epoll_wait 来等待事件 |

* 至此：epoll_wait 的协程就创建好了


epoll_wait  的协程代码:
| 源码 | 函数 | 调用了 | 被调函数 | 说明 |
| ---- | ---- | ---- | ---- | ---- |
| poll_default_linux.go:91 | func (p *defaultPoll) Wait() | - | - | epoll 事件循环 |


# 用户调用流程

| 源码 | 函数 | 调用了 | 被调函数 | 说明 |
| ---- | ---- | ---- | ---- | ---- |
| - | eventLoop.Serve(listener) | netpoll.go:49 | func (evl *eventLoop) Serve(ln net.Listener) | 开始卡住，执行事件循环 |
| netpoll.go:50 | func (evl *eventLoop) Serve | - | ConvertListener(ln) | 监听端口 |
| :56 | - | - | evl.svr.Run() | 执行事件循环 |
| netpoll_server.go:46 | func (s *server) Run() | - | - | - |
| :47 | - | - | s.operator = FDOperator{} | 创建 fd 管理的类 |
| :49 | - | - | OnRead: s.OnRead | 当 server fd 有事件时，走到 OnRead 去 |
| :52 | - | - | - | s.operator.poll = pollmanager.Pick() | 选择一个 poll 对象 |
| poll_loadbalance.go:89 | func (b *roundRobinLB) Pick() | - | - | 使用 roundRobin 算法，从 polls 数组中返回一个对象 |
｜ netpoll_server.go:53 ｜ - ｜ - ｜ s.operator.Control(PollReadable) ｜ 把 server fd 加到 epoll 中 |
| netpoll.go:59 | - | - | err = evl.waitQuit() | 程序在这里卡住，等到事件循环结束 |

## server fd 的事件
| 源码 | 函数 | 调用了 | 被调函数 | 说明 |
| ---- | ---- | ---- | ---- | ---- |
| netpoll_server.go:92 | func (s *server) OnRead(p Poll) | - | - | - |
| - | - | :94 | conn, err := s.ln.Accept() | server fd 的读事件发生，一定是用户接入产生的 |
| - | - | :109 | var connection = &connection{} | 创建连接对象 |
| - | - | :110 | connection.init(conn.(Conn), s.opts) | 初始化客户端连接对象 |
| connection_impl.go:320 | func (c *connection) init(conn Conn, opts *options) | - | - | - |
| - | - | :325 | c.inputBuffer, c.outputBuffer = NewLinkBuffer... | 初始化接收缓冲区和输出缓冲区 |
| - | - | :328 | c.initNetFD(conn) | 初始化客户端 fd |
| - | - | :329 | c.initFDOperator() | 初始化客户端 fd 上的回调 |
| :359 | func (c *connection) initFDOperator() | - | - | - |
| - | - | :360 | poll := pollmanager.Pick() | 为当前的客户端 fd 选择一个事件循环 |
| connection_impl.go:330 | - | - | c.initFinalizer() | 客户端连接对象的初始化 |
| - | - | :332 | syscall.SetNonblock(c.fd, true) | 客户端 fd 设置为非阻塞 |
| - | - | :344 | c.onPrepare(opts) | 触发 prepare 的事件 |

* 回调 prepare 后，server fd 的读事件就处理完了。
* 这个时候，client fd 已经加入了 epoll 事件循环了
  - client fd 的  epoll_ctl 在哪里调用的 ???

## 新用户  accept 流程
| 源码 | 函数 | 调用了 | 被调函数 | 说明 |
| ---- | ---- | ---- | ---- | ---- |
| net_listener.go:86 | func (ln *listener) Accept() | - | - | - |
| - | - | :92 | syscall.Accept(ln.fd) | 产生 client fd |
| - | - | :99 | var nfd = &netFD{} | 产生 client fd 对象 |

## 新用户，数据接收

首先，在 func (c *connection) initFDOperator() 中注册上去
然后，在 epoll 事件循环中被触发

| 源码 | 函数 | 调用了 | 被调函数 | 说明 |
| ---- | ---- | ---- | ---- | ---- |
| connection_reactor.go:83 | func (c *connection) inputs(vs [][]byte)  | - | - | - |

## onrequest 的触发流程
| 源码 | 函数 | 调用了 | 被调函数 | 说明 |
| ---- | ---- | ---- | ---- | ---- |
| connection_reactor.go:89 | func (c *connection) inputAck(n int) | - | - | - |
| - | - | - | :110 | needTrigger = c.onRequest() | readv 之后，触发 onrequest |
| connection_onevent.go:150 | func (c *connection) onRequest() | - | - | - |
| - | - | :151 | c.onRequestCallback.Load().(OnRequest) | 读出用户配置的函数 |
| - | - | :155 | c.onProcess() | 再调用 process 函数 |
| :170 | func (c *connection) onProcess() | - | - | - |
| - | - | :175 | if !c.lock(processing) | 回调之前要加锁 |
| - | - | :179 | var task = func() {...} | 包装一个长长的处理函数 | 
| - | - | :231 | runTask(c.ctx, task) | 默认使用协程池来执行 onRequest |

* OnRequest 会被多次触发，每当 epoll_wait 中有事件的时候，就会触发一次

## 新用户数据写入

* 客户端连接对象
net_netfd.go:32
type netFD struct   // 代表 client fd 的对象

* 链表 buffer
NewLinkBuffer()

* barrier
及其 barrier 池

* 内存池怎么设计的?
  - link buffer
* 协程池怎么设计的?
  - gopool
* 零拷贝是怎么支持的?
  - 没有支持零拷贝

* 为什么 read timeout, write timeout, onIdle 等都不生效?
* 如果包与包之间，到达服务器的间隔比较长，epoll 事件循环中对应的行为是怎么样的?
* 能不能设置 socket buffer ?
* 读事件产生后，数据究竟是怎么读进去的？
  - readv 系统调用，在 epoll_wait 协程中完成
* syscall 与  rawSyscall 的区别

* 依赖的组件：
  - github.com/bytedance/gopkg/lang/mcache  slab 内存池
  - gopool

* 因为 readv 调用，所以数据一定会至少发生一次拷贝
* ??? onRequest 只会被调用一次，除非要断掉这个连接，否则不应该退出 onRequest()
* ??? 用户倒底能不能主动关闭一个连接?
* mux/sharedQueue: 这个目录针对 rpc 框架又做了很多封装
* 为什么  client fd 没有注册写事件? 
  - 不需要，仅当 socket write buffer full 时，才需要注册
* 数据倒底是怎么发送出去的?
  - 用户把数据拷贝到 output buffer
  - 使用 sendmsg 系统调用把数据发出去
  - 如果 socket write buffer 写满，注册写事件
  - epoll_wait 协程中等待写事件触发，在事件循环的协程中再次发送
* 当一个连接再次来包，处理流程是怎么样的?
* 何时断开客户端的连接？

# 系统调用相关的背景知识
```
 1 typedef union epoll_data {
 2     void *ptr;
 3     int fd;
 4     __uint32_t u32;
 5     __uint64_t u64;
 6 } epoll_data_t;
 7 
 8 struct epoll_event {
 9     __uint32_t events; /* Epoll events */
10     epoll_data_t data; /* User data variable */
11 };
```

# 写事件触发流程


| 源码 | 函数 | 调用了 | 被调函数 | 说明 |
| ---- | ---- | ---- | ---- | ---- |
| poll_default_linux.go:118 | func (p *defaultPoll) handler(events []epollevent) | - | - | - |
| - | - | :196 | `if triggerWrite {` | 写事件开始处理了 |
| - | - | :205 | var n, err = iosend() | 使用系统调用发送数据 |
| net_io.go:39 | func iosend(fd int, bs [][]byte, ivs []syscall.Iovec, zerocopy bool) | - | - | - |
| - | - | :40 | sendmsg(fd, bs, ivs, zerocopy) | - |
| sys_sendmsg_linux.go:34 | func sendmsg() | - | - | 系统调用，相当于 writev |

* 仅当  socket write buffer full 的时候，才会注册写事件

* 学会使用，应该要读这些文件的注释：
  - connection.go
  - eventloop.go
  - nocopy.go
  - poll.go
